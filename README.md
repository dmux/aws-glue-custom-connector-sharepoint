# AWS Glue SharePoint Custom Connector

Um custom connector para AWS Glue que permite ler arquivos CSV e Excel diretamente de bibliotecas de documentos do SharePoint utilizando Microsoft Graph API.

## üìã Funcionalidades

- ‚úÖ Leitura de arquivos CSV (`.csv`)
- ‚úÖ Leitura de arquivos Excel (`.xls`, `.xlsx`)
- ‚úÖ Autentica√ß√£o via OAuth2 Client Credentials (Azure AD)
- ‚úÖ Integra√ß√£o nativa com AWS Glue 4.0+
- ‚úÖ Suporte ao Glue Studio
- ‚úÖ Processamento paralelo de arquivos
- ‚úÖ Logging estruturado e monitoramento

## üèóÔ∏è Arquitetura

```
AWS Glue Job
‚îú‚îÄ‚îÄ SharePoint Custom Connector (JAR)
‚îú‚îÄ‚îÄ Microsoft Graph API (OAuth2)
‚îú‚îÄ‚îÄ SharePoint Document Library
‚îî‚îÄ‚îÄ Spark DataFrame/DynamicFrame
```

## üîß Pr√©-requisitos

### Azure AD Application Setup

1. **Registrar Application no Azure AD:**

   - Acesse [Azure Portal](https://portal.azure.com)
   - Navegue para "Azure Active Directory" > "App registrations"
   - Clique em "New registration"
   - Configure:
     - Nome: `Glue SharePoint Connector`
     - Supported account types: `Accounts in this organizational directory only`
     - Redirect URI: (deixe vazio para Client Credentials flow)

2. **Configurar Permiss√µes:**

   ```
   Microsoft Graph API Permissions:
   - Sites.Read.All (Application)
   - Files.Read.All (Application)
   ```

3. **Criar Client Secret:**

   - V√° para "Certificates & secrets"
   - Clique em "New client secret"
   - Configure a expira√ß√£o desejada
   - **Copie o valor do secret imediatamente**

4. **Obter IDs necess√°rios:**
   - `Client ID`: Na p√°gina "Overview" da aplica√ß√£o
   - `Tenant ID`: Na p√°gina "Overview" da aplica√ß√£o
   - `Site ID`: Use Microsoft Graph Explorer ou PowerShell

### Obter SharePoint Site ID

**Op√ß√£o 1: Microsoft Graph Explorer**

```
GET https://graph.microsoft.com/v1.0/sites/{hostname}:/sites/{sitename}
```

**Op√ß√£o 2: PowerShell**

```powershell
Connect-PnPOnline -Url "https://yourtenant.sharepoint.com/sites/yoursite" -Interactive
Get-PnPSite | Select Id
```

## üöÄ Instala√ß√£o e Configura√ß√£o

### 1. Build do Projeto

```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd aws-glue-custom-connector-sharepoint

# Build do JAR
mvn clean package

# O JAR ser√° gerado em: target/sharepoint-connector-1.0.0.jar
```

### 2. Upload para S3

```bash
# Upload do JAR para S3
aws s3 cp target/sharepoint-connector-1.0.0.jar s3://your-bucket/glue-connectors/

# Verificar upload
aws s3 ls s3://your-bucket/glue-connectors/
```

### 3. Registro no AWS Glue

**Via AWS Console (Glue Studio):**

1. Acesse AWS Glue Studio
2. V√° para "Connectors" no menu lateral
3. Clique em "Create custom connector"
4. Configure:
   - **Name:** `SharePoint Connector`
   - **Connector type:** `Spark`
   - **Class name:** `com.aws.glue.connector.sharepoint.SharePointDataSourceFactory`
   - **JAR file path:** `s3://your-bucket/glue-connectors/sharepoint-connector-1.0.0.jar`

**Via AWS CLI:**

```bash
aws glue create-connection --connection-input '{
  "Name": "sharepoint-connector",
  "ConnectionType": "CUSTOM",
  "ConnectionProperties": {
    "CONNECTOR_URL": "s3://your-bucket/glue-connectors/sharepoint-connector-1.0.0.jar",
    "CONNECTOR_TYPE": "Spark",
    "CONNECTOR_CLASS_NAME": "com.aws.glue.connector.sharepoint.SharePointDataSourceFactory"
  }
}'
```

### 4. Configura√ß√£o da Connection

No AWS Glue Studio, ao criar uma Connection:

| Propriedade               | Valor                        | Obrigat√≥rio |
| ------------------------- | ---------------------------- | ----------- |
| `sharepoint.clientId`     | ID da aplica√ß√£o Azure AD     | ‚úÖ          |
| `sharepoint.clientSecret` | Secret da aplica√ß√£o Azure AD | ‚úÖ          |
| `sharepoint.tenantId`     | ID do tenant Azure AD        | ‚úÖ          |
| `sharepoint.siteId`       | ID do site SharePoint        | ‚úÖ          |

> ‚ö†Ô∏è **Importante:** Marque `sharepoint.clientSecret` como "hidden" para seguran√ßa.

## üìÇ Modos de Opera√ß√£o

O connector suporta dois modos de opera√ß√£o para localizar arquivos no SharePoint:

### 1. **Discovery Autom√°tico** (Padr√£o)

Quando n√£o especificado o par√¢metro `sharepoint.filePath`, o connector automaticamente:

- Lista todos os arquivos na raiz da biblioteca de documentos
- Filtra apenas arquivos suportados (`.csv`, `.xls`, `.xlsx`)
- Processa todos os arquivos encontrados

```python
# Modo autom√°tico - processa todos os arquivos CSV/Excel encontrados
sharepoint_options = {
    "sharepoint.clientId": "your-client-id",
    "sharepoint.clientSecret": "your-client-secret",
    "sharepoint.tenantId": "your-tenant-id",
    "sharepoint.siteId": "your-site-id"
}
```

### 2. **Arquivo Espec√≠fico**

Quando especificado o par√¢metro `sharepoint.filePath`, o connector:

- Acessa diretamente o arquivo no caminho especificado
- Suporta caminhos com subpastas
- Valida se o tipo de arquivo √© suportado

```python
# Modo espec√≠fico - processa apenas o arquivo indicado
sharepoint_options = {
    "sharepoint.clientId": "your-client-id",
    "sharepoint.clientSecret": "your-client-secret",
    "sharepoint.tenantId": "your-tenant-id",
    "sharepoint.siteId": "your-site-id",
    "sharepoint.filePath": "Reports/Monthly/sales-data.xlsx"  # Caminho espec√≠fico
}
```

### Exemplos de Caminhos

| Caminho                      | Descri√ß√£o                                                 |
| ---------------------------- | --------------------------------------------------------- |
| `data.csv`                   | Arquivo na raiz da biblioteca                             |
| `folder/data.csv`            | Arquivo em uma subpasta                                   |
| `Reports/2024/Q1/sales.xlsx` | Arquivo em estrutura hier√°rquica                          |
| `/Documents/report.csv`      | Caminho absoluto (barra inicial removida automaticamente) |

### Valida√ß√µes

- ‚úÖ Arquivo deve existir no caminho especificado
- ‚úÖ Extens√£o deve ser suportada (`.csv`, `.xls`, `.xlsx`)
- ‚úÖ Usu√°rio deve ter permiss√£o de leitura no arquivo
- ‚ùå N√£o suporta wildcards ou padr√µes de arquivo

## üíª Uso

### Em AWS Glue Studio

1. **Criar um novo Job:**

   - Escolha "Visual with a source and target"
   - Selecione "Custom connector" como source

2. **Configurar Source:**

   - Selecione o "SharePoint Connector"
   - Configure a Connection com as credenciais
   - Configure as propriedades de conex√£o

3. **Executar o Job:**
   - Configure target (S3, Database, etc.)
   - Execute o job

### Em Glue Job (C√≥digo Python)

```python
import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

# Configura√ß√£o das credenciais SharePoint
sharepoint_options = {
    "sharepoint.clientId": "your-client-id",
    "sharepoint.clientSecret": "your-client-secret",
    "sharepoint.tenantId": "your-tenant-id",
    "sharepoint.siteId": "your-site-id"
    # Opcional: especificar arquivo espec√≠fico
    # "sharepoint.filePath": "folder/subfolder/specific-file.csv"
}

# Inicializar contextos
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session

# Ler dados do SharePoint
df = spark.read \
    .format("com.aws.glue.connector.sharepoint.SharePointDataSourceFactory") \
    .options(**sharepoint_options) \
    .load()

# Converter para DynamicFrame
dynamic_frame = DynamicFrame.fromDF(df, glueContext, "sharepoint_data")

# Aplicar transforma√ß√µes
transformed = ApplyMapping.apply(frame=dynamic_frame, mappings=[
    ("Name", "string", "name", "string"),
    ("Age", "string", "age", "int"),
    ("City", "string", "city", "string")
])

# Escrever para S3
glueContext.write_dynamic_frame.from_options(
    frame=transformed,
    connection_type="s3",
    connection_options={
        "path": "s3://your-output-bucket/sharepoint-data/"
    },
    format="parquet"
)
```

### Em Glue Job (C√≥digo Scala)

```scala
import com.amazonaws.services.glue.GlueContext
import com.amazonaws.services.glue.util.GlueArgParser
import org.apache.spark.SparkContext
import org.apache.spark.sql.SparkSession

// Configura√ß√£o
val glueContext = new GlueContext(SparkContext.getOrCreate())
val spark = glueContext.getSparkSession

// Op√ß√µes de conex√£o SharePoint
val options = Map(
  "sharepoint.clientId" -> "your-client-id",
  "sharepoint.clientSecret" -> "your-client-secret",
  "sharepoint.tenantId" -> "your-tenant-id",
  "sharepoint.siteId" -> "your-site-id"
)

// Ler dados
val df = spark.read
  .format("com.aws.glue.connector.sharepoint.SharePointDataSourceFactory")
  .options(options)
  .load()

// Processar dados
df.show()
df.write.parquet("s3://your-output-bucket/sharepoint-data/")
```

## üß™ Testes

```bash
# Executar todos os testes
mvn test

# Executar testes com cobertura
mvn test jacoco:report

# Ver relat√≥rio de cobertura
open target/site/jacoco/index.html
```

### Estrutura de Testes

- **Unit Tests:** Testam componentes isoladamente
- **Integration Tests:** Testam fluxo completo com WireMock
- **Cobertura:** Meta de ‚â•80% de cobertura de c√≥digo

## üìä Monitoramento e Logs

### CloudWatch Logs

Os logs s√£o automaticamente enviados para CloudWatch:

```
Log Group: /aws-glue/jobs/{job-name}
Log Stream: {execution-id}
```

### M√©tricas Importantes

- Tempo de autentica√ß√£o SharePoint
- N√∫mero de arquivos processados
- Tempo de download por arquivo
- Erros de parsing

### Exemplo de Log

```
2023-05-23 10:30:15.123 [main] INFO  SharePointClient - Found 5 supported files in SharePoint library
2023-05-23 10:30:15.456 [main] INFO  SharePointClient - Downloaded file: report.csv (1.2 MB)
2023-05-23 10:30:16.789 [main] INFO  CsvFileParser - Successfully parsed 1000 rows from CSV file
```

## üîí Seguran√ßa

### Rota√ß√£o de Credentials

1. **No Azure AD:**

   - Gere um novo client secret
   - Mantenha o antigo ativo durante a transi√ß√£o

2. **No AWS Glue:**

   - Atualize a connection com o novo secret
   - Teste a conectividade

3. **Remo√ß√£o do antigo:**
   - Remova o client secret antigo do Azure AD

### Boas Pr√°ticas

- ‚úÖ Use client secrets com expira√ß√£o curta (6-12 meses)
- ‚úÖ Implemente rota√ß√£o autom√°tica quando poss√≠vel
- ‚úÖ Monitore logs de autentica√ß√£o
- ‚úÖ Use IAM roles para acesso ao S3
- ‚úÖ Mantenha o JAR em bucket privado

## üêõ Troubleshooting

### Erros Comuns

**1. Authentication Failed**

```
Cause: Credenciais inv√°lidas ou expiradas
Solution: Verificar client ID, secret e tenant ID
```

**2. Site Not Found**

```
Cause: Site ID incorreto ou sem permiss√£o
Solution: Verificar site ID e permiss√µes da aplica√ß√£o
```

**3. File Parse Error**

```
Cause: Arquivo corrompido ou formato n√£o suportado
Solution: Verificar integridade do arquivo
```

**4. OutOfMemory Error**

```
Cause: Arquivo muito grande para mem√≥ria dispon√≠vel
Solution: Aumentar recursos do Glue job ou implementar streaming
```

### Debug Mode

Para habilitar logs de debug, configure:

```python
spark.conf.set("spark.sql.adaptive.enabled", "false")
spark.conf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
```

## üîÑ Versionamento

- **v1.0.0** - Vers√£o inicial com suporte a CSV e Excel
- Siga [Semantic Versioning](https://semver.org/)

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudan√ßas (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üìû Suporte

Para suporte e d√∫vidas:

- Abra uma [Issue](../../issues)
- Consulte a [documenta√ß√£o oficial do AWS Glue](https://docs.aws.amazon.com/glue/)
- Consulte a [documenta√ß√£o do Microsoft Graph](https://docs.microsoft.com/en-us/graph/)
